---
title: "Аутентификация в Kubernetes в деталях. Часть 3: JWT, сертификаты"
date: "2024-04-25T04:02:52Z"
author: bubnovd
authorTwitter: bubnovdnet
image: "/img/k8s-auth/logo.jpg"
description: "Обзор Kuberenetes RBAC и методов аутентификации: сертификаты, JWT"
tags:
- k8s
- authentication
keywords:
- k8s
- kubernetes
- authentication
- certificate
- JWT
- RBAC
- openssl
showFullContent: false
readingTime: true
hideComments: false
---

https://kubernetes.io/docs/tasks/tls/manual-rotation-of-ca-certificates/
https://kubernetes.io/docs/setup/best-practices/certificates/
https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/#kubeconfig-additional-users

- нельзя отозвать серт
- взаимодействие компонентов
- в каком порядке менять серты
- плэйбук
- лучше позаботиться заранее
- oidc, bastillion

Crl
Sub ca
Заседание dnscrypt про сертификаты





Утек админский кубконфиг. Что делать?
TL;DR: уволиться, создать новый кластер, сменить CA и все сертификаты в кластере

В [первой части](/post/k8s-auth) мы рассмотрели разные способы аутентификации в kube apiserver: JWT и сертификаты
Во [второй части](/post/k8s-impersonate) увидели гибкость системы RBAC
В этой части будем бороться с утекшим конфигом


Утекший конфиг - ситуация нечастая, но и, будем честны, нередкая:
- Ноутбук админа могут украсть, а диск незашифрован
- Из-за мисконфига CI/CD конфиг или токен может утечь в логи, а оттуда к злоумышленнику
- Файл может быть закоммичен в гит репозиторий

Да, да - все мы такие умные и никто таких очевидных багов не допустит. Креды утекают только у тех, кто не читает bubnovd.net - для них и этот пост =)

Итак, у вас утек конфиг. Девелоперский, админский - неважно. [В Kubernetes нет CRL](https://github.com/kubernetes/kubernetes/issues/18982), значит этот конфиг будет действителен вплоть до окончания срока действия сертификата. В этот момент приходят мысли как надо было реализовать доступ к кластеру, наладить ACL и разграничитт доступы. Но, дерьмо уже случилось (ПОМЕНЯТЬ ТУТ) и нужно фиксить проблему сейчас.

Поскольку сертификат (конфиг) утек, то надо полагать, что секьюрити процессов в компании нет и бессысленно рассуждать тут как найти злоумышленника через аудит логи или особенности поведения. С этого момента кластер по умолчанию стоит считать скомпрометированным. А раз так, то единственным правильным решением будет поднять новый кластер. Всё! Остальные решения неправильные.

Спасибо что прочитали, увидимся в следующей части.


Конечно, я бы не стал писать целую статью про утечку конфига и как с эим жить, если б мы жили в идеальном мире. В мире IaC и GitOps всё ещё живут примитивные снежинки. Живут и прекрасно эволюционируют и умирать не собираются. И для такой снежинки проще принять факт ~~копрометания~~ компрометации и научиться жить с этими рисками в мире полном депрессии, страха постоянного наблюдения и утешких секретов. В таком мире один из возможных этапов эволюции (или деградации) - смена CA.

Раз сертифкат утек, а отозвать его нельзя, то нужно выпустить новый СA. Раз выпущен новый СА - нужно заново выпустить все сертификаты. Для этого нужно понять какие это "все", в каком порядке их выпускать и в каком порядке применять, чтобы минимизировать время простоя.



Все знают, что "kubernetes - это всего пять бинарей". Все они общаются между собой и аутентифицируются такими же сертификатами, как и пользователи, о которых мы подробно говорили в [первой части](ССЫЛКА_ТУТ)

![The components of a Kubernetes cluster](https://raw.githubusercontent.com/kubernetes/website/13dd6a817432249795b84e6f68bd8c4a7151c01d/static/images/docs/components-of-kubernetes.svg)

Все компоненты кластера общаются с `kube-apiserver`:
- etcd
- controller manager
- kubelet
- scheduler

Логика здесь простая:
1. Генерируем новый CA
2. Генерируем сертификаты для каждого экземпляра `kubelet`, `scheduler`, `controller-manager`, `apiserver`
2.1. Генерируем сертификаты для каждого экземпляра `etcd`, `kube-proxy`
3. Заставляем кластер доверять обоим СА - старому и новому
4. По очереди меняем сертификаты во всех компонентах и перезапускаем их. Так как класстер доверяет обоим СА - старые и новые версии компонентов буду работать вместе
5. Удаляем старый СА
6. ...
7. PROFIT!!!

Логика простая, а реализация сложная. Сложности добавляет то, что ванильных кластеров практически не существует - всегда есть какой-то CNI, мониторинг, Admission Controllers и они тоже должны быть настроены определенным образом и в определенное время. Единой инструкции тут нет и для каждого кластера стоит вырабатывать свой процесс. В этом посте в качестве подопытного будет Kubernetes v1.23.7 с Calico, задеплоеный kubeadm'ом.

В официальной доке хорошо написано:
- [о сертификатах](https://kubernetes.io/docs/setup/best-practices/certificates/)
- [работе с сертификатами kubeadm'ом](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-certs/)
- [смене СА](https://kubernetes.io/docs/tasks/tls/manual-rotation-of-ca-certificates/)

Попробуем разобраться как генерировать сертификаты, в каком порядке их менять и почему именно так.